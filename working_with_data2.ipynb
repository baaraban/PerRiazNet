{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 4177)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "url = \"data/abalone.data\"\n",
    "dataframe = pandas.read_csv(url, header=-1)\n",
    "\n",
    "dumm = pandas.get_dummies(dataframe, prefix=None, prefix_sep='_', dummy_na=False, columns=[0,8], sparse=False, drop_first=False)\n",
    "\n",
    "y = dumm.as_matrix(columns=dumm.columns[-28:])\n",
    "# y = dumm.as_matrix(columns=dumm.columns[-3:])\n",
    "X = dumm.as_matrix(columns=dumm.columns[:-28])\n",
    "#  = dumm.as_matrix(columns=)\n",
    "y.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2798, 28)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.datasets.samples_generator import make_moons\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "# # DATA FOR CLASSIFICATION\n",
    "# np.random.seed(0)\n",
    "# # X, y = make_blobs(n_samples=400, centers=2, n_features=2, cluster_std=0.1,random_state=0)\n",
    "# X, y = make_moons(n_samples=400, shuffle=True, noise=None,random_state=0)\n",
    "# plt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.Spectral)\n",
    "\n",
    "# reshaped_y = np.array(y).reshape(len(y),1)\n",
    "\n",
    "# enc = OneHotEncoder()\n",
    "# enc.fit(reshaped_y)\n",
    "# encoded_y = enc.transform(reshaped_y).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR FORWARD PASS\n",
    "def ReLU(x):\n",
    "    return x*(x > 0)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "\n",
    "def differentiate_ReLU(x):\n",
    "    x[x <= 0] = 0\n",
    "    x[x > 0] = 1\n",
    "    return x\n",
    "\n",
    "def differentiate_tanh(a_1):\n",
    "    return 1 - np.tanh(a_1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, neurons, x, y):\n",
    "        np.random.seed(2)\n",
    "        \n",
    "        self.W_1 = np.random.rand(neurons,x.shape[1])\n",
    "        self.W_15 = np.random.rand(neurons,neurons)\n",
    "        self.W_2 = np.random.rand(neurons,neurons)\n",
    "        self.W_25 = np.random.rand(neurons,neurons)\n",
    "        self.W_out = np.random.rand(y.shape[1],neurons)\n",
    "        self.W_ResNet = np.random.rand(y.shape[1],x.shape[1])\n",
    "        \n",
    "        self.b_1 = np.random.rand(neurons,1)\n",
    "        self.b_15 = np.random.rand(neurons,1)\n",
    "        self.b_2 = np.random.rand(neurons,1)\n",
    "        self.b_25 = np.random.rand(neurons,1)\n",
    "        self.b_out = np.random.rand(y.shape[1],1)\n",
    "        \n",
    "        \n",
    "    def train(self, epochs, batch_size, X_train, X_test, y_train, y_test):\n",
    "        for iteration in range(epochs):\n",
    "            for i in range(len(X_train)//batch_size):\n",
    "                hs = feedforward(nn, X_train[i:i+batch_size], y_train[i:i+batch_size])\n",
    "                gradient = get_gradient(nn, hs)\n",
    "                update_neural_network(nn, gradient)\n",
    "                \n",
    "            if (iteration%(epochs//1000)==0):\n",
    "                hs = feedforward(nn, X_test, y_test)\n",
    "                print(log_loss(y_test, hs['z_out'].T))\n",
    "                \n",
    "    \n",
    "        if(len(X_train)%batch_size != 0):\n",
    "            k = len(X_train)%batch_size\n",
    "        \n",
    "            hs = feedforward(nn, X_train[k:], y_train[k:])\n",
    "            gradient = get_gradient(nn, hs)\n",
    "            update_neural_network(nn, gradient)\n",
    "            \n",
    "\n",
    "def feedforward(network, x, y):\n",
    "        forward_path = dict()\n",
    "        \n",
    "        forward_path['x'] = x.T\n",
    "        forward_path['y'] = y.T\n",
    "        \n",
    "        forward_path['a_1'] = np.add(network.W_1.dot(forward_path['x']), network.b_1)\n",
    "        forward_path['z_1'] = np.tanh(forward_path['a_1'])\n",
    "        \n",
    "        forward_path['a_15'] = np.add(network.W_15.dot(forward_path['z_1']), network.b_15)\n",
    "        forward_path['z_15'] = np.tanh(forward_path['a_15'])\n",
    "        \n",
    "        forward_path['a_2'] = np.add(network.W_2.dot(forward_path['z_15']), network.b_2)\n",
    "        forward_path['z_2'] = ReLU(forward_path['a_2'])\n",
    "        \n",
    "        forward_path['a_25'] = np.add(network.W_2.dot(forward_path['z_2']), network.b_25)\n",
    "        forward_path['z_25'] = ReLU(forward_path['a_25'])\n",
    "        \n",
    "        forward_path['a_out_1'] = network.W_out.dot(forward_path['z_25'])\n",
    "        forward_path['a_out_2'] = network.W_ResNet.dot(forward_path['x'])\n",
    "        \n",
    "        forward_path['a_out'] = np.add(np.add(forward_path['a_out_1'], forward_path['a_out_2']), network.b_out)\n",
    "        forward_path['z_out'] = softmax(forward_path['a_out'])\n",
    "        \n",
    "        return forward_path\n",
    "        \n",
    "        \n",
    "def get_gradient(network, hidden_state):\n",
    "        gradient = dict()\n",
    "        \n",
    "        derivative_of_tanh = differentiate_tanh(hidden_state['a_1'])\n",
    "        derivative_of_ReLU = differentiate_ReLU(hidden_state['a_2'])\n",
    " \n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        delta_out = hidden_state['y'] - hidden_state['z_out'] \n",
    "\n",
    "        \n",
    "        \n",
    "        delta_25 = np.multiply(derivative_of_ReLU, network.W_out.T.dot(delta_out))\n",
    "        delta_2 = np.multiply(derivative_of_ReLU, network.W_25.T.dot(delta_25))\n",
    "        delta_15 = np.multiply(derivative_of_tanh, network.W_2.T.dot(delta_2))\n",
    "        delta_1 = np.multiply(derivative_of_tanh, network.W_15.T.dot(delta_15))\n",
    "            \n",
    "        dW_ResNet = delta_out.dot(hidden_state['x'].T)\n",
    "        dW_out = delta_out.dot(hidden_state['z_25'].T)\n",
    "        dW_25 = delta_2.dot(hidden_state['z_2'].T)\n",
    "        dW_2 = delta_2.dot(hidden_state['z_15'].T)\n",
    "        dW_15 = delta_15.dot(hidden_state['z_1'].T)\n",
    "        dW_1 = delta_1.dot(hidden_state['x'].T)\n",
    "        \n",
    "        gradient['W_1'] = dW_1\n",
    "        gradient['W_15'] = dW_15\n",
    "        gradient['W_2'] = dW_2\n",
    "        gradient['W_25'] = dW_25\n",
    "        gradient['W_out'] = dW_out\n",
    "        gradient['W_ResNet'] = dW_ResNet\n",
    "        \n",
    "        gradient['b_1'] = np.expand_dims(np.mean(delta_1, axis=1), axis=1)\n",
    "        gradient['b_15'] = np.expand_dims(np.mean(delta_15, axis=1), axis=1)\n",
    "        gradient['b_2'] = np.expand_dims(np.mean(delta_2, axis=1), axis=1)\n",
    "        gradient['b_25'] = np.expand_dims(np.mean(delta_25, axis=1), axis=1)\n",
    "        gradient['b_out'] = np.expand_dims(np.mean(delta_out, axis=1), axis=1)\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "def update_neural_network(network, gradient, learning_rate = 0.032):\n",
    "    network.W_1 += learning_rate * gradient['W_1']\n",
    "    network.W_15 += learning_rate * gradient['W_15']\n",
    "    network.W_2 += learning_rate * gradient['W_2']\n",
    "    network.W_out += learning_rate * gradient['W_out']\n",
    "    network.W_ResNet += learning_rate * gradient['W_ResNet']\n",
    "        \n",
    "    network.b_1 += learning_rate * gradient['b_1']\n",
    "    network.b_2 += learning_rate * gradient['b_2']\n",
    "    network.b_out += learning_rate * gradient['b_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.61239035668714\n",
      "2.6727813300805647\n",
      "2.3138763892361154\n",
      "2.2882216751274576\n",
      "2.2710431592924794\n",
      "2.258570841079809\n",
      "2.2491334350814705\n",
      "2.2417981850717097\n",
      "2.2359911087896953\n",
      "2.2313320768777176\n",
      "2.227554797960077\n",
      "2.224464823157208\n",
      "2.2219158743051586\n",
      "2.2197955974310624\n",
      "2.218016465608499\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-272ec7a959c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-0a6c2adc4c76>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mupdate_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-0a6c2adc4c76>\u001b[0m in \u001b[0;36mfeedforward\u001b[0;34m(network, x, y)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mforward_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_out_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_out_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mforward_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mforward_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8ebcb4f1b8c7>\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0me_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0me_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0me_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(65, X_train, y_train)\n",
    "nn.train(epochs = 20000,batch_size = 1,X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
